# SCCL: Exploring Self-image and Cross-image Consistency Learning for Remote Sensing Burned Area Segmentation
The increasing global wildfires in recent years have destroyed a large number of forests and wetlands. Non-contact remote sensing technologies for burned area segmentation (BAS) offer accurate identification and delineation of burned areas.

## Benchmark Datasets

- [BAS-AUS](https://drive.google.com/drive/folders/1So0dHK5-aKj1t6OmFhRGLh_0nsXbldZE?usp=sharing) 
- [BAS-EUR](https://drive.google.com/drive/folders/1kEGOuljxKxIYwH54sNH_Wqmw7Sf7tTw5?usp=sharing) 

## Experimental Results on BAS datasets

**TABLE I.** Quantitative comparisons on two BAS datasets. The best results are shown in **bold**.

![image](./figs/sota.png)  



![image](./figs/res.png)
**Fig. 2** Visual comparisons of different SOTA methods.
		This figure shows that our proposed method (Ours) consistently generates burned masks close to the Ground Truth (GT).
		Zoom in for details.

## Evaluation
> We use this [Saliency-Evaluation-Toolbox](https://github.com/jiwei0921/Saliency-Evaluation-Toolbox) for evaluating all RGB-T SOD results.
